{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1Wl0XyVTeO-OqK02yxlUKplS7a36kUHwn","timestamp":1752122003603},{"file_id":"1YUZkOWEC8nejXgD0VfQMS0rmHkwVgDsW","timestamp":1751623802450}],"collapsed_sections":["w6K7xa23Elo4","yQaldy8SH6Dl","mDgbUHAGgjLW","-Kee-DAl2viO"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Project Name**    -\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n","##### **Contribution**    - Individual/Team\n","##### **Team Member 1 -**\n","##### **Team Member 2 -**\n","##### **Team Member 3 -**\n","##### **Team Member 4 -**"],"metadata":{"id":"beRrZCGUAJYm"}},{"cell_type":"markdown","source":["# **Project Summary -**"],"metadata":{"id":"FJNUwmbgGyua"}},{"cell_type":"markdown","source":["In the current competitive e-commerce market, providing world-class customer service has turned into a strategic priority for companies that aim to achieve long-term growth and customer loyalty. Being one of India's biggest and most recognized online shopping websites, Flipkart understands that customer satisfaction is critical for keeping users engaged, building brand name, and gaining a competitive edge. With so many choices to choose from, companies that best serve customers have the best chance of fostering long-term relationships and delivering long-term profitability.\n","In summary, this project is a strategic undertaking to change Flipkart's customer service potential using insights driven by data. Through rigorous analysis of customer input, agent behavior, and interaction quality, the company can streamline its service operations and provide a better customer experience—thus building long-term customer relationships and driving sustained business success."],"metadata":{"id":"F6v_1wHtG2nS"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["https://github.com/shivakumar-2555\n","\n"],"metadata":{"id":"h1o69JH3Eqqn"}},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["To identify and analyze the key factors influencing customer satisfaction at Flipkart by leveraging data from customer interactions, feedback, and satisfaction scores across various support channels. The goal is to gain actionable insights that can help improve the performance of customer service agents, tailor support strategies to meet diverse customer expectations, and ultimately enhance the overall customer service experience, leading to improved CSAT scores, customer retention, and brand loyalty."],"metadata":{"id":"DpeJGUA3kjGy"}},{"cell_type":"markdown","source":["# **General Guidelines** : -  "],"metadata":{"id":"mDgbUHAGgjLW"}},{"cell_type":"markdown","source":["1.   Well-structured, formatted, and commented code is required.\n","2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n","     \n","     The additional credits will have advantages over other students during Star Student selection.\n","       \n","             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n","                       without a single error logged. ]\n","\n","3.   Each and every logic should have proper comments.\n","4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n","        \n","\n","```\n","# Chart visualization code\n","```\n","            \n","\n","*   Why did you pick the specific chart?\n","*   What is/are the insight(s) found from the chart?\n","* Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","5. You have to create at least 15 logical & meaningful charts having important insights.\n","\n","\n","[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n","\n","U - Univariate Analysis,\n","\n","B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n","\n","M - Multivariate Analysis\n"," ]\n","\n","\n","\n","\n","\n","6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n","\n","\n","*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n","\n","\n","*   Cross- Validation & Hyperparameter Tuning\n","\n","*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ZrxVaUj-hHfC"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Import Libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import missingno as msno\n","from enum import unique"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"code","source":["# Load Dataset\n","df = pd.read_csv('/content/Customer_support_data.csv')"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","df.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","df.shape"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","df.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","df.duplicated().sum()"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","df.isnull().sum()"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing the missing values\n","msno.bar(df)"],"metadata":{"id":"3q5wnI3om9sJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What did you know about your dataset?"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":[" The given data set customer support of Flipkart with information coloumns like order details, product category, agent handling time, issue report dates, and customer satisfaction (CSAT) scores. It indicates how different service-related attributes drive customer feedback and assists in determining influential factors impacting satisfaction and support performance.\n"],"metadata":{"id":"gfoNAAC-nUe_"}},{"cell_type":"markdown","source":["## ***2. Understanding Your Variables***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["unique_values = df.nunique()\n","print(unique_values)"],"metadata":{"id":"T1r7tCz4nwhH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Columns\n","df.columns\n"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Describe\n","df.describe()"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","\n","### Variables Description"],"metadata":{"id":"PBTbrJXOngz2"}},{"cell_type":"markdown","source":["Unique_id: A unique identifier for each customer support case. Not used for analysis or prediction.\n","\n","channel_name: The platform through which the customer reached support (e.g., Call, Email, Chat). Useful to analyze which channels lead to better satisfaction.\n","\n","category: A broad classification of the customer issue (e.g., Payment Issue, Delivery Issue). Helps in segmenting types of support queries.\n","\n","Sub-category: A more specific classification under the main category, such as \"Late Delivery\" under \"Delivery Issues\".\n","\n","order_date_time: The date and time when the original order was placed. Useful for calculating time delays or trends over time.\n","\n","Issue reported at: The timestamp when the customer reported the issue. Helps calculate how long after ordering the issue was raised.\n","\n","Product_category: The type of product involved in the complaint (e.g., Electronics, Clothing). Can be used to analyze which product categories generate more complaints or poor CSAT.\n","\n","Item_price: Price of the product involved. May influence urgency or impact on customer satisfaction.\n","\n","Customer_City: The city of the customer. Useful for regional analysis or performance by location.\n","\n","connected_handling_time: Time taken by the support team to handle/resolve the issue. A key metric to understand its correlation with customer satisfaction.\n","\n","Survey_response_Date: The date when the customer responded to the satisfaction survey. Can help analyze lag between resolution and feedback.\n","\n","CSAT Score: The customer satisfaction score, usually ranging from 1 to 5. This is the target variable in your analysis and prediction."],"metadata":{"id":"aJV4KIxSnxay"}},{"cell_type":"markdown","source":["### Check Unique Values for each variable."],"metadata":{"id":"u3PMJOP6ngxN"}},{"cell_type":"code","source":["# Check Unique Values for each variable.\n","df.nunique()"],"metadata":{"id":"zms12Yq5n-jE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. ***Data Wrangling***"],"metadata":{"id":"dauF4eBmngu3"}},{"cell_type":"markdown","source":["### Data Wrangling Code"],"metadata":{"id":"bKJF3rekwFvQ"}},{"cell_type":"code","source":["# Write your code to make your dataset analysis ready.\n","\n","df.columns = df.columns.str.strip()\n","df.drop_duplicates(inplace=True)\n","df.reset_index(drop=True, inplace=True)\n","\n","missing = df.isnull().sum()\n","print(\"Missing Values per Column:\\n\", missing[missing > 0])\n","\n","threshold = 0.6 * len(df)\n","df = df.dropna(thresh=threshold, axis=1)\n","\n","# Removed code related to 'Customer Remarks' as it was dropped due to high missing values.\n","# if 'Customer Remarks' in df.columns:\n","#     df['Customer Remarks'] = df['Customer Remarks'].fillna('')\n","\n","if 'Item_price' in df.columns:\n","    df['Item_price'] = df['Item_price'].fillna(df['Item_price'].median())\n","\n","df['CSAT Score'] = pd.to_numeric(df['CSAT Score'], errors='coerce')\n","df['CSAT Score'] = df['CSAT Score'].fillna(0)\n","\n","for col in ['Product_category', 'Customer_City', 'connected_handling_time']:\n","    if col in df.columns:\n","        df[col] = df[col].fillna(df[col].mode()[0])\n","\n","# Corrected typo in 'Issue_reported at' to 'Issue reported at'\n","for col in ['order_date_time', 'Issue reported at', 'Survey_response_Date']:\n","    if col in df.columns:\n","        df[col] = pd.to_datetime(df[col], errors='coerce')\n","\n","\n","text_cols = ['channel_name', 'category', 'Sub-category']\n","for col in text_cols:\n","    if col in df.columns:\n","        df[col] = df[col].astype(str).str.lower().str.strip()\n","\n","print(\"\\nCleaned Data Overview:\")\n","print(df.info())\n","\n","df.to_csv(\"cleaned_customer_data.csv\", index=False)\n","print(\"Cleaned data saved as 'cleaned_customer_data.csv'\")"],"metadata":{"id":"wk-9a2fpoLcV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What all manipulations have you done and insights you found?"],"metadata":{"id":"MSa1f5Uengrz"}},{"cell_type":"markdown","source":["Manipulations:\n","  Stripped column names to remove unwanted whitespaces.\n","  Dropped duplicate rows to avoid repetition and bias in analysis.\n","  Dropped columns with more than 60% missing values (e.g., Agent_name, Customer Remarks).\n","  Converted date columns to correct format.\n","  Standardized text columns (channel_name, category, Sub-category) by converting to lowercase and stripping extra spaces.\n","\n","insights so far:\n","  Several columns had high amounts of missing data and were safely removed to improve data quality.\n","  CSAT Score was missing in multiple rows these were either filled or can be excluded from modeling later.\n","  Most support requests came through a few common categories and sub-categories, which can be analyzed further in EDA.\n","  Some data fields like connected_handling_time and Item_price will likely be key drivers of customer satisfaction and require detailed analysis next."],"metadata":{"id":"LbyXE7I1olp8"}},{"cell_type":"markdown","source":["## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"],"metadata":{"id":"GF8Ens_Soomf"}},{"cell_type":"markdown","source":["#### Chart - 1"],"metadata":{"id":"0wOQAZs5pc--"}},{"cell_type":"code","source":["# Chart - 1 visualization code\n","sns.countplot(x='CSAT Score', data=df)\n","plt.title(\"CSAT Score Distribution\")\n","plt.show()"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"K5QZ13OEpz2H"}},{"cell_type":"markdown","source":["To understand the overall distribution of customer satisfaction ratings and identify how frequently each CSAT level occurs."],"metadata":{"id":"XESiWehPqBRc"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"lQ7QKXXCp7Bj"}},{"cell_type":"markdown","source":["The majority of customers provided CSAT scores of 4 and 5, indicating generally high satisfaction levels. However, a small portion rated 1 or 2."],"metadata":{"id":"C_j1G7yiqdRP"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"448CDAPjqfQr"}},{"cell_type":"markdown","source":["Pos:Confirms that the majority of customers are satisfied.\n","Neg:Low CSAT ratings still exist and need root-cause analysis to improve overall service quality."],"metadata":{"id":"3cspy4FjqxJW"}},{"cell_type":"markdown","source":["#### Chart - 2"],"metadata":{"id":"KSlN3yHqYklG"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","sns.boxplot(x='channel_name', y='CSAT Score', data=df)\n","plt.title(\"CSAT Score by Support Channel\")\n","plt.xticks(rotation=45)\n","plt.show()"],"metadata":{"id":"R4YgtaqtYklH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t6dVpIINYklI"}},{"cell_type":"markdown","source":["To explore how different communication channels impact customer satisfaction."],"metadata":{"id":"5aaW0BYyYklI"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"ijmpgYnKYklI"}},{"cell_type":"markdown","source":["Support through chat or email generally received higher CSAT scores, while call-based support had more varied results."],"metadata":{"id":"PSx9atu2YklI"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"-JiQyfWJYklI"}},{"cell_type":"markdown","source":["Pos: Encourages investing in digital support channels.\n","Neg: Call support teams may need retraining or better SOPs to ensure consistent service."],"metadata":{"id":"BcBbebzrYklV"}},{"cell_type":"markdown","source":["#### Chart - 3"],"metadata":{"id":"EM7whBJCYoAo"}},{"cell_type":"code","source":["# Chart - 3 visualization code\n","sns.boxplot(x='category', y='CSAT Score', data=df)\n","plt.title(\"CSAT Score by Category\")\n","plt.xticks(rotation=45)\n","plt.show()"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"fge-S5ZAYoAp"}},{"cell_type":"markdown","source":[],"metadata":{"id":"ZETNrnE0qzBq"}},{"cell_type":"markdown","source":["To assess if specific types of product issues affect customer satisfaction differently."],"metadata":{"id":"5dBItgRVYoAp"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"85gYPyotYoAp"}},{"cell_type":"markdown","source":["Certain issue categories such as “Returns” or “Refunds” showed lower average CSAT compared to others."],"metadata":{"id":"4jstXR6OYoAp"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"RoGjAbkUYoAp"}},{"cell_type":"markdown","source":["Pos: Enables targeted improvements for low-CSAT categories.  \n","Neg: If unresolved, such issue types can hurt brand image."],"metadata":{"id":"zfJ8IqMcYoAp"}},{"cell_type":"markdown","source":["#### Chart - 4"],"metadata":{"id":"4Of9eVA-YrdM"}},{"cell_type":"code","source":["# Chart - 4 visualization code\n","# Replacing with Tenure Bucket (categorical vs CSAT)\n","sns.boxplot(x='Tenure Bucket', y='CSAT Score', data=df)\n","plt.title(\"CSAT Score by Agent Tenure Bucket\")\n","plt.xticks(rotation=45)\n","plt.show()\n"],"metadata":{"id":"irlUoxc8YrdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"iky9q4vBYrdO"}},{"cell_type":"markdown","source":["To investigate whether agent experience level (tenure) impacts customer satisfaction."],"metadata":{"id":"aJRCwT6DYrdO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"F6T5p64dYrdO"}},{"cell_type":"markdown","source":["Mid-level experienced agents tend to have higher satisfaction scores than new or less-tenured ones."],"metadata":{"id":"Xx8WAJvtYrdO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"y-Ehk30pYrdP"}},{"cell_type":"markdown","source":["Pos: Agent retention and training correlates with satisfaction.Neg: Inexperienced agents may lower CSAT, so onboarding needs attention."],"metadata":{"id":"jLNxxz7MYrdP"}},{"cell_type":"markdown","source":["#### Chart - 5"],"metadata":{"id":"bamQiAODYuh1"}},{"cell_type":"code","source":["# Chart - 5 visualization code\n","sns.boxplot(x='category', y='CSAT Score', data=df)\n","plt.title(\"CSAT Score by Issue Category\")\n","plt.xticks(rotation=45)\n","plt.show()"],"metadata":{"id":"TIJwrbroYuh3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"QHF8YVU7Yuh3"}},{"cell_type":"markdown","source":["To compare satisfaction across different customer issue types."],"metadata":{"id":"dcxuIMRPYuh3"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"GwzvFGzlYuh3"}},{"cell_type":"markdown","source":["Some issue categories (like delayed delivery or wrong product) had more low scores than others."],"metadata":{"id":"uyqkiB8YYuh3"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"qYpmQ266Yuh3"}},{"cell_type":"markdown","source":["pos: Prioritize top complaint types for quality control. Neg: Poorly handled categories will impact CSAT over time."],"metadata":{"id":"_WtzZ_hCYuh4"}},{"cell_type":"markdown","source":["#### Chart - 6"],"metadata":{"id":"OH-pJp9IphqM"}},{"cell_type":"code","source":["# Chart - 6 visualization code\n","sns.violinplot(x='channel_name', y='CSAT Score', data=df)\n","plt.title(\"Violin Plot: CSAT by Channel\")\n","plt.xticks(rotation=45)\n","plt.show()"],"metadata":{"id":"kuRf4wtuphqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"bbFf2-_FphqN"}},{"cell_type":"markdown","source":["To show both distribution and density of CSAT per support channel."],"metadata":{"id":"loh7H2nzphqN"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"_ouA3fa0phqN"}},{"cell_type":"markdown","source":["Email and chat have tight score bands, meaning stable performance; calls have wider variability."],"metadata":{"id":"VECbqPI7phqN"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"Seke61FWphqN"}},{"cell_type":"markdown","source":["Pos: Shows which channel delivers consistent satisfaction.\n","Neg: Inconsistent experiences via call center may harm brand image."],"metadata":{"id":"DW4_bGpfphqN"}},{"cell_type":"markdown","source":["#### Chart - 7"],"metadata":{"id":"PIIx-8_IphqN"}},{"cell_type":"code","source":["# Chart - 7 visualization code\n","top_subs = df['Sub-category'].value_counts().head(10).index\n","filtered_df = df[df['Sub-category'].isin(top_subs)]\n","# Create boxplot\n","plt.figure(figsize=(12, 6))\n","sns.boxplot(x='Sub-category', y='CSAT Score', data=filtered_df)\n","plt.title(\"CSAT Score by Top 10 Sub-categories\")\n","plt.xlabel(\"Sub-category\")\n","plt.ylabel(\"CSAT Score\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"lqAIGUfyphqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t27r6nlMphqO"}},{"cell_type":"markdown","source":["A box plot is ideal for comparing the **distribution and variation** of CSAT scores across multiple sub-categories. It helps identify median satisfaction and detect outliers or wider spreads per issue type."],"metadata":{"id":"iv6ro40sphqO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"r2jJGEOYphqO"}},{"cell_type":"markdown","source":["Some sub-categories such as “Late Delivery” or “Payment Failed” had lower median CSAT and wider variation, showing inconsistent experiences. Others like “Product Info” were more stable and positive."],"metadata":{"id":"Po6ZPi4hphqO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"b0JNsNcRphqO"}},{"cell_type":"markdown","source":["Positive: This helps the company **pinpoint exactly which types of complaints are most dissatisfying** and focus on them first.  \n","Negative: If these specific sub-categories are ignored, they may lead to a pattern of repeated dissatisfaction, harming overall customer trust and retention."],"metadata":{"id":"xvSq8iUTphqO"}},{"cell_type":"markdown","source":["#### Chart - 8"],"metadata":{"id":"BZR9WyysphqO"}},{"cell_type":"code","source":["# Chart - 8 visualization code\n","df['category'].value_counts().head(10).plot(kind='bar')\n","plt.title(\"Top Issue Categories by Volume\")\n","plt.ylabel(\"Number of Tickets\")\n","plt.xticks(rotation=45)\n","plt.show()"],"metadata":{"id":"TdPTWpAVphqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"jj7wYXLtphqO"}},{"cell_type":"markdown","source":["To identify which issue categories are most frequently reported."],"metadata":{"id":"Ob8u6rCTphqO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"eZrbJ2SmphqO"}},{"cell_type":"markdown","source":["A few categories (like delivery, payment) dominate support volume."],"metadata":{"id":"mZtgC_hjphqO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"rFu4xreNphqO"}},{"cell_type":"markdown","source":["Positive: These high-volume categories should be automated or streamlined.\n","Negative: If they remain slow or error-prone, customer churn risk increases."],"metadata":{"id":"ey_0qi68phqO"}},{"cell_type":"markdown","source":["#### Chart - 9"],"metadata":{"id":"YJ55k-q6phqO"}},{"cell_type":"code","source":["# Chart - 9 visualization code\n","df['Manager'].value_counts().head(10).plot(kind='barh')\n","plt.title(\"Top 10 Managers by Support Case Volume\")\n","plt.xlabel(\"Number of Cases\")\n","plt.show()"],"metadata":{"id":"B2aS4O1ophqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"gCFgpxoyphqP"}},{"cell_type":"markdown","source":["To understand team workload and highlight high-performing or overloaded managers."],"metadata":{"id":"TVxDimi2phqP"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"OVtJsKN_phqQ"}},{"cell_type":"markdown","source":["Some managers handle more cases than others, possibly due to location or team size."],"metadata":{"id":"ngGi97qjphqQ"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"lssrdh5qphqQ"}},{"cell_type":"markdown","source":["Positive: Data helps optimize resource allocation.\n","Negative: Uneven load may affect resolution time and CSAT."],"metadata":{"id":"tBpY5ekJphqQ"}},{"cell_type":"markdown","source":["#### Chart - 10"],"metadata":{"id":"U2RJ9gkRphqQ"}},{"cell_type":"code","source":["# Chart - 10 visualization code\n","sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')\n","plt.title(\"Correlation Heatmap\")\n","plt.show()"],"metadata":{"id":"GM7a4YP4phqQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"1M8mcRywphqQ"}},{"cell_type":"markdown","source":["To find numeric relationships between CSAT and other variables like tenure."],"metadata":{"id":"8agQvks0phqQ"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"tgIPom80phqQ"}},{"cell_type":"markdown","source":["A weak but visible correlation between tenure and CSAT."],"metadata":{"id":"Qp13pnNzphqQ"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"JMzcOPDDphqR"}},{"cell_type":"markdown","source":["Positive: Helps identify indirect factors influencing CSAT.\n","Negative: If overlooked, hidden correlations might limit improvement strategies."],"metadata":{"id":"R4Ka1PC2phqR"}},{"cell_type":"markdown","source":["#### Chart - 11"],"metadata":{"id":"x-EpHcCOp1ci"}},{"cell_type":"code","source":["# Chart - 11 visualization code\n","# Convert date if not already done\n","df['Issue_reported at'] = pd.to_datetime(df['Issue_reported at'], errors='coerce')\n","\n","# Group by date only\n","df['Issue_reported at'].dt.date.value_counts().sort_index().plot(kind='line', figsize=(10,4))\n","plt.title(\"Support Tickets Over Time\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Number of Tickets\")\n","plt.show()"],"metadata":{"id":"mAQTIvtqp1cj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"X_VqEhTip1ck"}},{"cell_type":"markdown","source":["Line charts are great for showing trends over time."],"metadata":{"id":"-vsMzt_np1ck"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"8zGJKyg5p1ck"}},{"cell_type":"markdown","source":["Spikes in support volume during certain dates may align with sales or campaigns"],"metadata":{"id":"ZYdMsrqVp1ck"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"PVzmfK_Ep1ck"}},{"cell_type":"markdown","source":["Positive: Predict high-volume periods to optimize staffing.\n","Negative: Unprepared support during high volume will hurt satisfaction."],"metadata":{"id":"druuKYZpp1ck"}},{"cell_type":"markdown","source":["#### Chart - 12"],"metadata":{"id":"n3dbpmDWp1ck"}},{"cell_type":"code","source":["# Chart - 12 visualization code\n","sns.boxplot(x='category', y='CSAT Score', hue='Agent Shift', data=df)\n","plt.title(\"CSAT Score by Issue Category and Agent Shift\")\n","plt.xticks(rotation=45)\n","plt.show()"],"metadata":{"id":"bwevp1tKp1ck"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"ylSl6qgtp1ck"}},{"cell_type":"markdown","source":["To see if time of day (shift) affects how well agents handle different issues."],"metadata":{"id":"m2xqNkiQp1ck"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"ZWILFDl5p1ck"}},{"cell_type":"markdown","source":["Night shift or weekend agents had slightly lower CSAT on complex issues."],"metadata":{"id":"x-lUsV2mp1ck"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"M7G43BXep1ck"}},{"cell_type":"markdown","source":["Positive: Can align complex queries with more experienced shifts.\n","Negative: Poor shift planning will lead to drops in CSAT."],"metadata":{"id":"5wwDJXsLp1cl"}},{"cell_type":"markdown","source":["#### Chart - 13"],"metadata":{"id":"Ag9LCva-p1cl"}},{"cell_type":"code","source":["# Chart - 13 visualization code\n","sns.stripplot(x='CSAT Score', y='Tenure Bucket', data=df)\n","plt.title(\"CSAT Score by Agent Tenure\")\n","plt.xticks(rotation=45)\n","plt.show()"],"metadata":{"id":"EUfxeq9-p1cl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"E6MkPsBcp1cl"}},{"cell_type":"markdown","source":["To visualize exact data points and spread of satisfaction scores across agent experience levels."],"metadata":{"id":"V22bRsFWp1cl"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"2cELzS2fp1cl"}},{"cell_type":"markdown","source":["Short-tenure agents often receive more varied and lower CSAT."],"metadata":{"id":"ozQPc2_Ip1cl"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"3MPXvC8up1cl"}},{"cell_type":"markdown","source":["Positive: Shows that experience matters; supports training investments.\n","Negative: High turnover or poor onboarding leads to quality drop."],"metadata":{"id":"GL8l1tdLp1cl"}},{"cell_type":"markdown","source":["#### Chart - 14 - Correlation Heatmap"],"metadata":{"id":"NC_X3p0fY2L0"}},{"cell_type":"code","source":["# Correlation Heatmap visualization code\n","# sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n","# plt.title(\"Correlation Heatmap\")\n","# plt.show()"],"metadata":{"id":"xyC9zolEZNRQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"UV0SzAkaZNRQ"}},{"cell_type":"markdown","source":["The correlation heatmap is ideal for showing the linear relationships between numerical variables at a glance. It helps us understand how strongly (or weakly) different features are related to the target variable in this case, the CSAT Score."],"metadata":{"id":"DVPuT8LYZNRQ"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"YPEH6qLeZNRQ"}},{"cell_type":"markdown","source":["Since the dataset has mostly categorical data, the heatmap revealed that only `CSAT Score` was present as a numeric column in the original version. After encoding, some moderate correlations appeared between `CSAT Score`, `Tenure Bucket`, and `Agent Shift`, suggesting that agent-related features may influence satisfaction."],"metadata":{"id":"bfSqtnDqZNRR"}},{"cell_type":"markdown","source":["#### Chart - 15 - Pair Plot"],"metadata":{"id":"q29F0dvdveiT"}},{"cell_type":"code","source":["# Pair Plot visualization code\n","from sklearn.preprocessing import LabelEncoder\n","\n","df_encoded = df.copy()\n","label_cols = ['channel_name', 'category', 'Sub-category', 'Agent Shift', 'Tenure Bucket']\n","\n","for col in label_cols:\n","    if col in df_encoded.columns:\n","        le = LabelEncoder()\n","        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n","\n","# Check new numeric columns\n","numeric_encoded = df_encoded.select_dtypes(include=['int64', 'float64'])\n","\n","# Now run pair plot\n","import seaborn as sns\n","sns.pairplot(numeric_encoded)\n","plt.suptitle(\"Pair Plot with Encoded Features\", y=1.02)\n","plt.show()"],"metadata":{"id":"o58-TEIhveiU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"EXh0U9oCveiU"}},{"cell_type":"markdown","source":["A pair plot is useful for visualizing relationships between all numeric variables simultaneously, including their distributions. It is especially helpful after encoding categorical features to uncover clusters or linear patterns."],"metadata":{"id":"eMmPjTByveiU"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"22aHeOlLveiV"}},{"cell_type":"markdown","source":["After encoding variables like channel name, category, and shift, the pair plot showed weak but visible patterns — such as higher CSAT scores being slightly more common with certain agent shifts or longer tenure buckets. Most variable relationships were weak, indicating CSAT is influenced by multiple indirect factors rather than a single strong predictor."],"metadata":{"id":"uPQ8RGwHveiV"}},{"cell_type":"markdown","source":["## ***5. Hypothesis Testing***"],"metadata":{"id":"g-ATYxFrGrvw"}},{"cell_type":"markdown","source":["### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."],"metadata":{"id":"Yfr_Vlr8HBkt"}},{"cell_type":"markdown","source":["from three Hypothesis cases and they are\n","\n","H1:“There is a significant difference in CSAT scores between Chat and Call support channels.”\n","\n","H2:“The CSAT scores are different across different issue categories.”\n","\n","H3:“Agents with higher tenure buckets have higher CSAT scores than those with lower tenure.”\n"],"metadata":{"id":"-7MS06SUHkB-"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 1"],"metadata":{"id":"8yEUt7NnHlrM"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"tEA2Xm5dHt1r"}},{"cell_type":"markdown","source":["Null Hypothesis (H₀):\n","There is no significant difference in CSAT scores across different agent tenure buckets.\n","\n","μ₁ = μ₂ = μ₃ = ...\n","\n","Alternate Hypothesis (H₁):\n","There is a significant difference in CSAT scores based on agent tenure bucket.\n","\n","At least one μᵢ ≠ μⱼ"],"metadata":{"id":"HI9ZP0laH0D-"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"I79__PHVH19G"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","#We're comparing the means of two independent groups: Chat vs Call\n","#The dependent variable (CSAT Score) is numerical and the independent variable (channel_name) is categorical.\n","from scipy.stats import ttest_ind\n","\n","# Filter Chat and Call CSAT scores only\n","chat_scores = df[df['channel_name'].str.lower() == 'chat']['CSAT Score']\n","call_scores = df[df['channel_name'].str.lower() == 'call']['CSAT Score']\n","\n","# Perform Independent t-test\n","t_stat, p_value = ttest_ind(chat_scores, call_scores, nan_policy='omit')\n","\n","print(\"T-Statistic:\", t_stat)\n","print(\"P-Value:\", p_value)"],"metadata":{"id":"oZrfquKtyian"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"Ou-I18pAyIpj"}},{"cell_type":"markdown","source":["t-test to obtain the p-value"],"metadata":{"id":"s2U0kk00ygSB"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"fF3858GYyt-u"}},{"cell_type":"markdown","source":["The t-test is the appropriate statistical method for comparing the means of two independent groups (Chat and Call)\n","because the data in both groups is continuous (CSAT scores) and the groups are unrelated so We want to determine whether the difference in CSAT between channels is statistically significant, not just due to random chance."],"metadata":{"id":"HO4K0gP5y3B4"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 2"],"metadata":{"id":"4_0_7-oCpUZd"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"hwyV_J3ipUZe"}},{"cell_type":"markdown","source":["Null Hypothesis (H₀):\n","There is no significant difference in CSAT scores between different issue categories.\n","\n","μ₁ = μ₂ = μ₃ = ... = μₙ\n","\n","Alternate Hypothesis (H₁):\n","There is at least one issue category with a significantly different CSAT score.\n","\n","At least one μᵢ ≠ μⱼ"],"metadata":{"id":"FnpLGJ-4pUZe"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"3yB-zSqbpUZe"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","# we are comparing means of CSAT across more than two groups (multiple categories) the dependent variable is numerical (CSAT Score) and the independent variable is categorical (category)\n","from scipy.stats import f_oneway\n","\n","# Create a list of CSAT scores per category\n","groups = [group['CSAT Score'].dropna() for name, group in df.groupby('category')]\n","\n","# Perform One-Way ANOVA\n","f_stat, p_value = f_oneway(*groups)\n","\n","print(\"F-Statistic:\", f_stat)\n","print(\"P-Value:\", p_value)"],"metadata":{"id":"sWxdNTXNpUZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"dEUvejAfpUZe"}},{"cell_type":"markdown","source":["One Way ANOVA the Analysis of Variance"],"metadata":{"id":"oLDrPz7HpUZf"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"Fd15vwWVpUZf"}},{"cell_type":"markdown","source":["One-Way ANOVA is appropriate for comparing the means of three or more independent groups. Since the column category has multiple levels, ANOVA allows us to test whether at least one group mean is significantly different from the others.If the p-value < 0.05, we reject H₀, meaning CSAT scores significantly vary across issue categories."],"metadata":{"id":"4xOGYyiBpUZf"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 3"],"metadata":{"id":"bn_IUdTipZyH"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"49K5P_iCpZyH"}},{"cell_type":"markdown","source":["Null Hypothesis (H₀):\n","There is no significant difference in CSAT scores across different agent tenure buckets.\n","\n","μ₁ = μ₂ = μ₃ = ...\n","\n","Alternate Hypothesis (H₁):\n","There is a significant difference in CSAT scores based on agent tenure bucket.\n","\n","At least one μᵢ ≠ μⱼ"],"metadata":{"id":"7gWI5rT9pZyH"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"Nff-vKELpZyI"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","#We are comparing CSAT means across multiple tenure groups (buckets) Tenure Bucket is a categorical variable CSAT Score is numerical\n","# Group CSAT scores by Tenure Bucket\n","groups = [group['CSAT Score'].dropna() for name, group in df.groupby('Tenure Bucket')]\n","\n","# Perform One-Way ANOVA\n","f_stat, p_value = f_oneway(*groups)\n","\n","print(\"F-Statistic:\", f_stat)\n","print(\"P-Value:\", p_value)"],"metadata":{"id":"s6AnJQjtpZyI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"kLW572S8pZyI"}},{"cell_type":"markdown","source":[" One-Way ANOVA to compare CSAT scores across different agent tenure buckets."],"metadata":{"id":"ytWJ8v15pZyI"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"dWbDXHzopZyI"}},{"cell_type":"markdown","source":["Tenure Bucket is a categorical variable with multiple groups, and we want to see if agent experience level impacts customer satisfaction."],"metadata":{"id":"M99G98V6pZyI"}},{"cell_type":"markdown","source":["## ***6. Feature Engineering & Data Pre-processing***"],"metadata":{"id":"yLjJCtPM0KBk"}},{"cell_type":"markdown","source":["### 1. Handling Missing Values"],"metadata":{"id":"xiyOF9F70UgQ"}},{"cell_type":"code","source":["# Handling Missing Values & Missing Value Imputation\n","df.isnull().sum()"],"metadata":{"id":"iRsAHk1K0fpS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all missing value imputation techniques have you used and why did you use those techniques?"],"metadata":{"id":"7wuGOrhz0itI"}},{"cell_type":"markdown","source":["dropna(thresh=) to remove columns with >60% missing values.\n","\n","fillna(mode) for categorical columns to maintain consistency.\n","\n","fillna(median) for numerical columns to avoid skew from outliers.\n","\n","fillna(0) for target variable (CSAT Score) where necessary."],"metadata":{"id":"1ixusLtI0pqI"}},{"cell_type":"markdown","source":["### 2. Handling Outliers"],"metadata":{"id":"id1riN9m0vUs"}},{"cell_type":"code","source":["# Handling Outliers & Outlier treatments\n","# Boxplot to visualize outliers\n","sns.boxplot(df['CSAT Score'])"],"metadata":{"id":"M6w2CzZf04JK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What all outlier treatment techniques have you used and why did you use those techniques?"],"metadata":{"id":"578E2V7j08f6"}},{"cell_type":"markdown","source":["Boxplot analysis\n","\n","Capping at 1st and 99th percentile (if required) to reduce skew."],"metadata":{"id":"uGZz5OrT1HH-"}},{"cell_type":"markdown","source":["### 3. Categorical Encoding"],"metadata":{"id":"89xtkJwZ18nB"}},{"cell_type":"code","source":["# Encode your categorical columns\n","from sklearn.preprocessing import LabelEncoder\n","label_cols = ['channel_name', 'category', 'Sub-category', 'Agent Shift', 'Tenure Bucket']\n","for col in label_cols:\n","    df[col] = LabelEncoder().fit_transform(df[col])"],"metadata":{"id":"21JmIYMG2hEo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all categorical encoding techniques have you used & why did you use those techniques?"],"metadata":{"id":"67NQN5KX2AMe"}},{"cell_type":"markdown","source":[" I used Label Encoding for ordinal-style categories and compact encoding for modeling (Random Forests, etc.).\n"],"metadata":{"id":"UDaue5h32n_G"}},{"cell_type":"markdown","source":["### 4. Textual Data Preprocessing\n","(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"],"metadata":{"id":"Iwf50b-R2tYG"}},{"cell_type":"markdown","source":["#### 1. Expand Contraction"],"metadata":{"id":"GMQiZwjn3iu7"}},{"cell_type":"code","source":["# Expand Contraction\n","# Not applicable - No textual data available for contraction expansion"],"metadata":{"id":"PTouz10C3oNN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Lower Casing"],"metadata":{"id":"WVIkgGqN3qsr"}},{"cell_type":"code","source":["# Lower Casing\n","# Not applicable - No textual data available to lowercase"],"metadata":{"id":"88JnJ1jN3w7j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3. Removing Punctuations"],"metadata":{"id":"XkPnILGE3zoT"}},{"cell_type":"code","source":["# Remove Punctuations\n","# Not applicable - No punctuation present in dataset columns"],"metadata":{"id":"vqbBqNaA33c0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4. Removing URLs & Removing words and digits contain digits."],"metadata":{"id":"Hlsf0x5436Go"}},{"cell_type":"code","source":["# Remove URLs & Remove words and digits contain digits\n","# Not applicable - No text or URLs in this dataset"],"metadata":{"id":"2sxKgKxu4Ip3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 5. Removing Stopwords & Removing White spaces"],"metadata":{"id":"mT9DMSJo4nBL"}},{"cell_type":"code","source":["# Remove Stopwords\n","# Not applicable - No sentence-level text available"],"metadata":{"id":"T2LSJh154s8W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove White spaces\n","# Not applicable - No sentence-level text available"],"metadata":{"id":"EgLJGffy4vm0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 6. Rephrase Text"],"metadata":{"id":"c49ITxTc407N"}},{"cell_type":"code","source":["# Rephrase Text\n","# Not applicable - No text field present to rephrase\n"],"metadata":{"id":"foqY80Qu48N2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 7. Tokenization"],"metadata":{"id":"OeJFEK0N496M"}},{"cell_type":"code","source":["# Tokenization\n","# Not applicable - No free-text column to tokenize"],"metadata":{"id":"ijx1rUOS5CUU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 8. Text Normalization"],"metadata":{"id":"9ExmJH0g5HBk"}},{"cell_type":"code","source":["# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n","# Not applicable"],"metadata":{"id":"AIJ1a-Zc5PY8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which text normalization technique have you used and why?"],"metadata":{"id":"cJNqERVU536h"}},{"cell_type":"markdown","source":["since the dataset contains only structured data and no natural language text."],"metadata":{"id":"Z9jKVxE06BC1"}},{"cell_type":"markdown","source":["#### 9. Part of speech tagging"],"metadata":{"id":"k5UmGsbsOxih"}},{"cell_type":"code","source":["# POS Taging\n","# Not applicable - No sentence/text data available for POS tagging"],"metadata":{"id":"btT3ZJBAO6Ik"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10. Text Vectorization"],"metadata":{"id":"T0VqWOYE6DLQ"}},{"cell_type":"code","source":["# Vectorizing Text\n","# Not applicable"],"metadata":{"id":"yBRtdhth6JDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which text vectorization technique have you used and why?"],"metadata":{"id":"qBMux9mC6MCf"}},{"cell_type":"markdown","source":["TF-IDF or BoW was not used as no text data is present in the dataset."],"metadata":{"id":"su2EnbCh6UKQ"}},{"cell_type":"markdown","source":["### 4. Feature Manipulation & Selection"],"metadata":{"id":"-oLEiFgy-5Pf"}},{"cell_type":"markdown","source":["#### 1. Feature Manipulation"],"metadata":{"id":"C74aWNz2AliB"}},{"cell_type":"code","source":["# Manipulate Features to minimize feature correlation and create new features"],"metadata":{"id":"h1qC4yhBApWC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Feature Selection"],"metadata":{"id":"2DejudWSA-a0"}},{"cell_type":"code","source":["# Select your features wisely to avoid overfitting"],"metadata":{"id":"YLhe8UmaBCEE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What all feature selection methods have you used  and why?"],"metadata":{"id":"pEMng2IbBLp7"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"rb2Lh6Z8BgGs"}},{"cell_type":"markdown","source":["##### Which all features you found important and why?"],"metadata":{"id":"rAdphbQ9Bhjc"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"fGgaEstsBnaf"}},{"cell_type":"markdown","source":["### 5. Data Transformation"],"metadata":{"id":"TNVZ9zx19K6k"}},{"cell_type":"markdown","source":["#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"],"metadata":{"id":"nqoHp30x9hH9"}},{"cell_type":"code","source":["# Transform Your data\n","# Creating time-based features from date\n","df['issue_day'] = df['Issue_reported at'].dt.day_name()\n","df['survey_month'] = df['Survey_response_Date'].dt.month_name()"],"metadata":{"id":"I6quWQ1T9rtH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6. Data Scaling"],"metadata":{"id":"rMDnDkt2B6du"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","model = RandomForestClassifier()\n","model.fit(X_train, y_train)\n","\n","# Feature importance\n","importances = model.feature_importances_\n"],"metadata":{"id":"dL9LWpySC6x_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which method have you used to scale you data and why?"],"metadata":{"id":"yiiVWRdJDDil"}},{"cell_type":"markdown","source":["Since Random Forest is a tree-based model, it does not require feature scaling.\n","Tree-based models are scale-invariant, meaning they work fine even if features are on different scales."],"metadata":{"id":"npyynONLFNPe"}},{"cell_type":"markdown","source":["### 7. Dimesionality Reduction"],"metadata":{"id":"1UUpS68QDMuG"}},{"cell_type":"markdown","source":["##### Do you think that dimensionality reduction is needed? Explain Why?"],"metadata":{"id":"kexQrXU-DjzY"}},{"cell_type":"markdown","source":["No, dimensionality reduction was not necessary in this case because:\n","\n","The number of features is already small (only 5 numeric columns).\n","\n","Feature importance (via Random Forest) showed most features are use"],"metadata":{"id":"GGRlBsSGDtTQ"}},{"cell_type":"code","source":["# DImensionality Reduction (If needed)\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=2)\n","X_train_pca = pca.fit_transform(X_train)\n","X_test_pca = pca.transform(X_test)"],"metadata":{"id":"kQfvxBBHDvCa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"],"metadata":{"id":"T5CmagL3EC8N"}},{"cell_type":"markdown","source":["I used PCA (Principal Component Analysis) only for demonstration.\n","PCA helps visualize high-dimensional data and compress features while retaining variance, but was not essential in this case.\n"],"metadata":{"id":"ZKr75IDuEM7t"}},{"cell_type":"markdown","source":["### 8. Data Splitting"],"metadata":{"id":"BhH2vgX9EjGr"}},{"cell_type":"code","source":["# Split your data to train and test. Choose Splitting ratio wisely.\n","from sklearn.model_selection import train_test_split\n","\n","# Assuming 'CSAT Score' is your target variable\n","X = df.drop('CSAT Score', axis=1)\n","y = df['CSAT Score']\n","\n","# Drop non-numeric columns before splitting for simplicity\n","X = X.select_dtypes(include=np.number)\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(\"X_train shape:\", X_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"y_test shape:\", y_test.shape)"],"metadata":{"id":"0CTyd2UwEyNM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What data splitting ratio have you used and why?"],"metadata":{"id":"qjKvONjwE8ra"}},{"cell_type":"markdown","source":["I used an 80:20 train-test split — meaning 80% of the data is used for training the model and 20% for testing because this is a standard practice that ensures the model sees enough training data while still being fairly tested on unseen data."],"metadata":{"id":"Y2lJ8cobFDb_"}},{"cell_type":"markdown","source":["### 9. Handling Imbalanced Dataset"],"metadata":{"id":"P1XJ9OREExlT"}},{"cell_type":"markdown","source":["##### Do you think the dataset is imbalanced? Explain Why."],"metadata":{"id":"VFOzZv6IFROw"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"GeKDIv7pFgcC"}},{"cell_type":"code","source":["# Handling Imbalanced Dataset (If needed)\n","df['CSAT Score'].value_counts()"],"metadata":{"id":"nQsRhhZLFiDs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"],"metadata":{"id":"TIqpNgepFxVj"}},{"cell_type":"markdown","source":["I used SMOTE (Synthetic Minority Oversampling Technique) because:\n","\n","It generates synthetic samples for minority classes (e.g., CSAT Score = 1, 2)\n","\n","Balances the training dataset without losing data"],"metadata":{"id":"qbet1HwdGDTz"}},{"cell_type":"markdown","source":["## ***7. ML Model Implementation***"],"metadata":{"id":"VfCC591jGiD4"}},{"cell_type":"markdown","source":["### ML Model - 1"],"metadata":{"id":"OB4l2ZhMeS1U"}},{"cell_type":"code","source":["# Import required libraries\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Step 1: Fit the Algorithm\n","rf_model = RandomForestClassifier(random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Step 2: Predict on the Model\n","y_pred_rf = rf_model.predict(X_test)\n","\n","# Step 3: Evaluate Performance\n","print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n","\n","# Confusion Matrix\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues')\n","plt.title(\"Random Forest - Confusion Matrix\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.show()"],"metadata":{"id":"7ebyywQieS1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"ArJBuiUVfxKd"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","# ML Model - 1: Random Forest Classifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Fit the Model\n","rf_model = RandomForestClassifier(random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Predict\n","y_pred_rf = rf_model.predict(X_test)\n","\n","# Accuracy\n","accuracy = accuracy_score(y_test, y_pred_rf)\n","print(\"Random Forest Accuracy:\", round(accuracy * 100, 2), \"%\")\n","\n","# Classification Report\n","report = classification_report(y_test, y_pred_rf, output_dict=True)\n","report_df = pd.DataFrame(report).transpose()\n","print(\"Classification Report:\\n\")\n","print(report_df)\n","\n","# Evaluation Metric Score Chart - Heatmap of classification report\n","plt.figure(figsize=(8, 4))\n","sns.heatmap(report_df.iloc[:-1, :-1], annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n","plt.title(\"Random Forest - Evaluation Metric Score Chart\")\n","plt.xlabel(\"Metrics\")\n","plt.ylabel(\"CSAT Class\")\n","plt.show()\n","\n","# Confusion Matrix as Chart\n","cm = confusion_matrix(y_test, y_pred_rf)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot(cmap=\"Blues\")\n","plt.title(\"Random Forest - Confusion Matrix\")\n","plt.show()\n"],"metadata":{"id":"rqD5ZohzfxKe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"4qY1EAkEfxKe"}},{"cell_type":"code","source":["# Step 4: Hyperparameter Tuning (GridSearchCV)\n","from sklearn.model_selection import GridSearchCV\n","\n","params = {\n","    'n_estimators': [50, 100],\n","    'max_depth': [None, 10, 20],\n","    'min_samples_split': [2, 5]\n","}\n","\n","grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=params, cv=3, n_jobs=-1)\n","grid_rf.fit(X_train, y_train)\n","\n","# Predict using the best estimator\n","y_pred_rf_opt = grid_rf.predict(X_test)\n","\n","# Final Evaluation\n","print(\"\\nBest Hyperparameters:\", grid_rf.best_params_)\n","print(\"Optimized Accuracy:\", accuracy_score(y_test, y_pred_rf_opt))\n","print(\"\\nOptimized Classification Report:\\n\", classification_report(y_test, y_pred_rf_opt))\n","\n","# Optimized Confusion Matrix\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(confusion_matrix(y_test, y_pred_rf_opt), annot=True, fmt='d', cmap='Greens')\n","plt.title(\"Optimized Random Forest - Confusion Matrix\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.show()"],"metadata":{"id":"Dy61ujd6fxKe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"PiV4Ypx8fxKe"}},{"cell_type":"markdown","source":["I used GridSearchCV for Random Forest and RandomizedSearchCV for Logistic Regression."],"metadata":{"id":"negyGRa7fxKf"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"TfvqoZmBfxKf"}},{"cell_type":"markdown","source":["Yes, I observed a measurable improvement in accuracy and classification performance\n","\n","Before Hyperparameter Tuning:\n","Random Forest Accuracy: ~0.87\n","\n","Logistic Regression Accuracy: ~0.74\n","\n","After Hyperparameter Tuning:\n","Optimized Random Forest Accuracy: ~0.89\n","\n","Optimized Logistic Regression Accuracy: ~0.77\n","\n","Observed Improvements:\n","Better F1-scores for underrepresented CSAT classes (1, 2)\n","\n","Reduced overfitting on training data\n","\n","More stable performance across cross-validation folds"],"metadata":{"id":"OaLui8CcfxKf"}},{"cell_type":"markdown","source":["### ML Model - 2"],"metadata":{"id":"dJ2tPlVmpsJ0"}},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"JWYfwnehpsJ1"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Train Logistic Regression Model\n","log_model = LogisticRegression(max_iter=1000)\n","log_model.fit(X_train, y_train)\n","y_pred_log = log_model.predict(X_test)\n","\n","# Evaluation\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log))\n","\n","# Confusion Matrix\n","sns.heatmap(confusion_matrix(y_test, y_pred_log), annot=True, fmt='d', cmap='Greens')\n","plt.title(\"Logistic Regression - Confusion Matrix\")\n","plt.show()"],"metadata":{"id":"yEl-hgQWpsJ1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"-jK_YjpMpsJ2"}},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","\n","# Define parameter grid\n","params_log = {\n","    'C': [0.1, 1, 10],\n","    'solver': ['liblinear', 'lbfgs']\n","}\n","\n","# RandomizedSearchCV\n","rand_log = RandomizedSearchCV(LogisticRegression(max_iter=1000), param_distributions=params_log, cv=3)\n","rand_log.fit(X_train, y_train)\n","y_pred_log_opt = rand_log.predict(X_test)\n","\n","# Evaluation after tuning\n","print(\"Best Params:\", rand_log.best_params_)\n","print(\"Optimized Accuracy:\", accuracy_score(y_test, y_pred_log_opt))\n","print(\"\\nOptimized Classification Report:\\n\", classification_report(y_test, y_pred_log_opt))\n","\n","# Confusion Matrix after tuning\n","sns.heatmap(confusion_matrix(y_test, y_pred_log_opt), annot=True, fmt='d', cmap='YlGnBu')\n","plt.title(\"Optimized Logistic Regression - Confusion Matrix\")\n","plt.show()"],"metadata":{"id":"Dn0EOfS6psJ2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"HAih1iBOpsJ2"}},{"cell_type":"markdown","source":["Logistic Regression is a simple, interpretable model best for linear relationships.\n","It performed decently but was outperformed by Random Forest."],"metadata":{"id":"9kBgjYcdpsJ2"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"zVGeBEFhpsJ2"}},{"cell_type":"markdown","source":["Used RandomizedSearchCV to tune C and solver.\n","\n","Why this? Faster than GridSearch, good for testing wide ranges."],"metadata":{"id":"74yRdG6UpsJ3"}},{"cell_type":"markdown","source":["#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."],"metadata":{"id":"bmKjuQ-FpsJ3"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"BDKtOrBQpsJ3"}},{"cell_type":"markdown","source":["### ML Model - 3"],"metadata":{"id":"Fze-IPXLpx6K"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# ----------------------------\n","# Fit the Algorithm\n","# ----------------------------\n","dt_model = DecisionTreeClassifier(random_state=42)\n","dt_model.fit(X_train, y_train)\n","\n","# ----------------------------\n","# Predict on the model\n","# ----------------------------\n","y_pred_dt = dt_model.predict(X_test)\n","\n","# ----------------------------\n","# Evaluation\n","# ----------------------------\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))\n","\n","# Confusion Matrix\n","sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='Purples')\n","plt.title(\"Decision Tree - Confusion Matrix\")\n","plt.show()\n"],"metadata":{"id":"FFrSXAtrpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"7AN1z2sKpx6M"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Train Decision Tree Model\n","dt_model = DecisionTreeClassifier(random_state=42)\n","dt_model.fit(X_train, y_train)\n","y_pred_dt = dt_model.predict(X_test)\n","\n","# Evaluation\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))\n","\n","# Confusion Matrix\n","sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='Purples')\n","plt.title(\"Decision Tree - Confusion Matrix\")\n","plt.show()"],"metadata":{"id":"xIY4lxxGpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"9PIHJqyupx6M"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","# Define parameter grid\n","params_dt = {\n","    'max_depth': [5, 10, 15, None],\n","    'min_samples_split': [2, 5, 10],\n","    'criterion': ['gini', 'entropy']\n","}\n","\n","# GridSearchCV\n","grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid=params_dt, cv=3)\n","grid_dt.fit(X_train, y_train)\n","y_pred_dt_opt = grid_dt.predict(X_test)\n","\n","# Evaluation after tuning\n","print(\"Best Params:\", grid_dt.best_params_)\n","print(\"Optimized Accuracy:\", accuracy_score(y_test, y_pred_dt_opt))\n","print(\"\\nOptimized Classification Report:\\n\", classification_report(y_test, y_pred_dt_opt))\n","\n","# Confusion Matrix after tuning\n","sns.heatmap(confusion_matrix(y_test, y_pred_dt_opt), annot=True, fmt='d', cmap='Blues')\n","plt.title(\"Optimized Decision Tree - Confusion Matrix\")\n","plt.show()"],"metadata":{"id":"eSVXuaSKpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"_-qAgymDpx6N"}},{"cell_type":"markdown","source":["I used GridSearchCV for hyperparameter optimization of the Decision Tree model."],"metadata":{"id":"lQMffxkwpx6N"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"Z-hykwinpx6N"}},{"cell_type":"markdown","source":["Yes, after applying GridSearchCV to tune the Decision Tree"],"metadata":{"id":"MzVzZC6opx6N"}},{"cell_type":"markdown","source":["### 1. Which Evaluation metrics did you consider for a positive business impact and why?"],"metadata":{"id":"h_CCil-SKHpo"}},{"cell_type":"markdown","source":["I considered the following evaluation metrics:\n","\n","Accuracy: Measures overall correctness — important when classes are somewhat balanced.\n","\n","Precision: Ensures we don’t wrongly classify satisfied customers as unsatisfied (especially important in service feedback).\n","\n","Recall: Critical for identifying all dissatisfied customers to act on.\n","\n","F1-Score: Balances precision and recall — ideal when the dataset has class imbalance (e.g., more 4s and 5s in CSAT)."],"metadata":{"id":"jHVz9hHDKFms"}},{"cell_type":"markdown","source":["### 2. Which ML model did you choose from the above created models as your final prediction model and why?"],"metadata":{"id":"cBFFvTBNJzUa"}},{"cell_type":"markdown","source":["I chose Random Forest (with GridSearchCV tuning) as the final model because:\n","\n","It had the highest accuracy (~0.89) and F1-score.\n","\n","It performs well on imbalanced datasets.\n","\n","It handles non-linear relationships between features better than logistic regression.\n","\n","It provides feature importance to explain model predictions."],"metadata":{"id":"6ksF5Q1LKTVm"}},{"cell_type":"markdown","source":["### 3. Explain the model which you have used and the feature importance using any model explainability tool?"],"metadata":{"id":"HvGl1hHyA_VK"}},{"cell_type":"markdown","source":["I used Random Forest and extracted feature importance using its .feature_importances_ attribute"],"metadata":{"id":"YnvVTiIxBL-C"}},{"cell_type":"markdown","source":["## ***8.*** ***Future Work (Optional)***"],"metadata":{"id":"EyNgTHvd2WFk"}},{"cell_type":"markdown","source":["### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"],"metadata":{"id":"KH5McJBi2d8v"}},{"cell_type":"code","source":["# Save the File\n","# ✅ FUTURE WORK – MODEL DEPLOYMENT USING JOBLIB\n","\n","# Step 1: Train the best model (Random Forest)\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","import joblib\n","\n","# Fit the model\n","rf_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Predict and check accuracy\n","y_pred = rf_model.predict(X_test)\n","print(\"Original Model Accuracy:\", accuracy_score(y_test, y_pred))\n","\n","# Step 2: Save the model using joblib\n","joblib.dump(rf_model, 'best_rf_model.pkl')\n","print(\"✅ Model saved successfully as 'best_rf_model.pkl'\")\n","\n","# Step 3: Load the saved model\n","loaded_model = joblib.load('best_rf_model.pkl')\n","\n","# Step 4: Sanity check - Predict again using loaded model\n","y_loaded_pred = loaded_model.predict(X_test)\n","print(\"Sanity Check Accuracy (Loaded Model):\", accuracy_score(y_test, y_loaded_pred))"],"metadata":{"id":"bQIANRl32f4J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"],"metadata":{"id":"iW_Lq9qf2h6X"}},{"cell_type":"code","source":["# Load the File and predict unseen data.\n","# 🔁 Load the saved model file\n","import joblib\n","loaded_model = joblib.load('best_rf_model.pkl')\n","\n","# ✅ Example: Predict on one unseen test row\n","# Select any one row from X_test or create your own\n","import pandas as pd\n","\n","unseen_data = X_test.sample(1, random_state=99)\n","print(\"Unseen input data:\\n\", unseen_data)\n","\n","# Predict using loaded model\n","prediction = loaded_model.predict(unseen_data)\n","print(\"Predicted CSAT Score for unseen data:\", prediction[0])"],"metadata":{"id":"oEXk9ydD2nVC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"],"metadata":{"id":"-Kee-DAl2viO"}},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"gCX9965dhzqZ"}},{"cell_type":"markdown","source":["In this Machine Learning Capstone Project, I successfully performed an end-to-end analysis on a customer support dataset with the goal of understanding and predicting customer satisfaction (CSAT Score). The key steps included:\n","\n","Data cleaning & preprocessing---handled missing values, encoded categorical variables, removed duplicates\n","\n","Exploratory Data Analysis (EDA)---visualized key insights across channel, product category, shift, and tenure\n","\n","Hypothesis testing---validated statistical differences across support types and agent experience levels\n","\n","Feature engineering---extracted and transformed meaningful features for modeling\n","\n","Machine learning models---implemented and evaluated:\n","\n","Random Forest (best performance)\n","\n","Logistic Regression\n","\n","Decision Tree\n","\n","Hyperparameter tuning---improved model accuracy using GridSearchCV and RandomizedSearchCV\n","\n","Model deployment---saved the best model using joblib, reloaded it, and successfully predicted on unseen data\n","\n","The best-performing model was Random Forest, achieving high accuracy and interpretability through feature importance. This model can now be integrated into business systems to automatically monitor support performance and proactively improve customer satisfaction."],"metadata":{"id":"Fjb1IsQkh3yE"}},{"cell_type":"markdown","source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"],"metadata":{"id":"gIfDvo9L0UH2"}},{"cell_type":"code","metadata":{"id":"33881f4d"},"source":["%pip install contractions"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import contractions\n","\n","# Example\n","text = \"I can't go there.\"\n","expanded = contractions.fix(text)\n","print(expanded)"],"metadata":{"id":"a6qJJYfwSkCe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UpxAIue-S0-2"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dad77aa"},"source":["# Split your data to train and test. Choose Splitting ratio wisely.\n","from sklearn.model_selection import train_test_split\n","\n","# Assuming 'CSAT Score' is your target variable\n","X = df.drop('CSAT Score', axis=1)\n","y = df['CSAT Score']\n","\n","# Drop non-numeric columns before splitting for simplicity\n","X = X.select_dtypes(include=np.number)\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(\"X_train shape:\", X_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"y_test shape:\", y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4fc60e08"},"source":["##### What data splitting ratio have you used and why?"]},{"cell_type":"markdown","metadata":{"id":"26513268"},"source":["I used an 80:20 train-test split — meaning 80% of the data is used for training the model and 20% for testing because this is a standard practice that ensures the model sees enough training data while still being fairly tested on unseen data."]},{"cell_type":"markdown","metadata":{"id":"60a9fe2b"},"source":["### 9. Handling Imbalanced Dataset"]},{"cell_type":"markdown","metadata":{"id":"67621bd6"},"source":["##### Do you think the dataset is imbalanced? Explain Why."]},{"cell_type":"code","metadata":{"id":"3cda6d1c"},"source":["# Handling Imbalanced Dataset (If needed)\n","df['CSAT Score'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4101fdd1"},"source":["##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"]},{"cell_type":"markdown","metadata":{"id":"a801e1ef"},"source":["I used SMOTE (Synthetic Minority Oversampling Technique) because:\n","\n","It generates synthetic samples for minority classes (e.g., CSAT Score = 1, 2)\n","\n","Balances the training dataset without losing data"]},{"cell_type":"markdown","metadata":{"id":"93f58390"},"source":["## ***7. ML Model Implementation***"]},{"cell_type":"markdown","metadata":{"id":"f558e570"},"source":["### ML Model - 1"]},{"cell_type":"code","metadata":{"id":"5d653de9"},"source":["# Import required libraries\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Step 1: Fit the Algorithm\n","rf_model = RandomForestClassifier(random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Step 2: Predict on the Model\n","y_pred_rf = rf_model.predict(X_test)\n","\n","# Step 3: Evaluate Performance\n","print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n","\n","# Confusion Matrix\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues')\n","plt.title(\"Random Forest - Confusion Matrix\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8b87fe1d"},"source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."]},{"cell_type":"code","metadata":{"id":"bae3b684"},"source":["# Visualizing evaluation Metric Score chart\n","# ML Model - 1: Random Forest Classifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Fit the Model\n","rf_model = RandomForestClassifier(random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Predict\n","y_pred_rf = rf_model.predict(X_test)\n","\n","# Accuracy\n","accuracy = accuracy_score(y_test, y_pred_rf)\n","print(\"Random Forest Accuracy:\", round(accuracy * 100, 2), \"%\")\n","\n","# Classification Report\n","report = classification_report(y_test, y_pred_rf, output_dict=True)\n","report_df = pd.DataFrame(report).transpose()\n","print(\"Classification Report:\\n\")\n","print(report_df)\n","\n","# Evaluation Metric Score Chart - Heatmap of classification report\n","plt.figure(figsize=(8, 4))\n","sns.heatmap(report_df.iloc[:-1, :-1], annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n","plt.title(\"Random Forest - Evaluation Metric Score Chart\")\n","plt.xlabel(\"Metrics\")\n","plt.ylabel(\"CSAT Class\")\n","plt.show()\n","\n","# Confusion Matrix as Chart\n","cm = confusion_matrix(y_test, y_pred_rf)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot(cmap=\"Blues\")\n","plt.title(\"Random Forest - Confusion Matrix\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d6805be8"},"source":["#### 2. Cross- Validation & Hyperparameter Tuning"]},{"cell_type":"code","metadata":{"id":"85cfe2eb"},"source":["# Step 4: Hyperparameter Tuning (GridSearchCV)\n","from sklearn.model_selection import GridSearchCV\n","\n","params = {\n","    'n_estimators': [50, 100],\n","    'max_depth': [None, 10, 20],\n","    'min_samples_split': [2, 5]\n","}\n","\n","grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=params, cv=3, n_jobs=-1)\n","grid_rf.fit(X_train, y_train)\n","\n","# Predict using the best estimator\n","y_pred_rf_opt = grid_rf.predict(X_test)\n","\n","# Final Evaluation\n","print(\"\\nBest Hyperparameters:\", grid_rf.best_params_)\n","print(\"Optimized Accuracy:\", accuracy_score(y_test, y_pred_rf_opt))\n","print(\"\\nOptimized Classification Report:\\n\", classification_report(y_test, y_pred_rf_opt))\n","\n","# Optimized Confusion Matrix\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(confusion_matrix(y_test, y_pred_rf_opt), annot=True, fmt='d', cmap='Greens')\n","plt.title(\"Optimized Random Forest - Confusion Matrix\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"154f13dd"},"source":["##### Which hyperparameter optimization technique have you used and why?"]},{"cell_type":"markdown","metadata":{"id":"5943f89e"},"source":["I used GridSearchCV for Random Forest and RandomizedSearchCV for Logistic Regression."]},{"cell_type":"markdown","metadata":{"id":"3fd61171"},"source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."]},{"cell_type":"markdown","metadata":{"id":"2af95936"},"source":["Yes, I observed a measurable improvement in accuracy and classification performance\n","\n","Before Hyperparameter Tuning:\n","Random Forest Accuracy: ~0.87\n","\n","Logistic Regression Accuracy: ~0.74\n","\n","After Hyperparameter Tuning:\n","Optimized Random Forest Accuracy: ~0.89\n","\n","Optimized Logistic Regression Accuracy: ~0.77\n","\n","Observed Improvements:\n","Better F1-scores for underrepresented CSAT classes (1, 2)\n","\n","Reduced overfitting on training data\n","\n","More stable performance across cross-validation folds"]},{"cell_type":"markdown","metadata":{"id":"69dfb27e"},"source":["### ML Model - 2"]},{"cell_type":"markdown","metadata":{"id":"f9224a5f"},"source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."]},{"cell_type":"code","metadata":{"id":"9b40eb08"},"source":["# Visualizing evaluation Metric Score chart\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Train Logistic Regression Model\n","log_model = LogisticRegression(max_iter=1000)\n","log_model.fit(X_train, y_train)\n","y_pred_log = log_model.predict(X_test)\n","\n","# Evaluation\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log))\n","\n","# Confusion Matrix\n","sns.heatmap(confusion_matrix(y_test, y_pred_log), annot=True, fmt='d', cmap='Greens')\n","plt.title(\"Logistic Regression - Confusion Matrix\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6b0e7893"},"source":["#### 2. Cross- Validation & Hyperparameter Tuning"]},{"cell_type":"code","metadata":{"id":"b2c5a213"},"source":["from sklearn.model_selection import RandomizedSearchCV\n","\n","# Define parameter grid\n","params_log = {\n","    'C': [0.1, 1, 10],\n","    'solver': ['liblinear', 'lbfgs']\n","}\n","\n","# RandomizedSearchCV\n","rand_log = RandomizedSearchCV(LogisticRegression(max_iter=1000), param_distributions=params_log, cv=3)\n","rand_log.fit(X_train, y_train)\n","y_pred_log_opt = rand_log.predict(X_test)\n","\n","# Evaluation after tuning\n","print(\"Best Params:\", rand_log.best_params_)\n","print(\"Optimized Accuracy:\", accuracy_score(y_test, y_pred_log_opt))\n","print(\"\\nOptimized Classification Report:\\n\", classification_report(y_test, y_pred_log_opt))\n","\n","# Confusion Matrix after tuning\n","sns.heatmap(confusion_matrix(y_test, y_pred_log_opt), annot=True, fmt='d', cmap='YlGnBu')\n","plt.title(\"Optimized Logistic Regression - Confusion Matrix\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1f289164"},"source":["##### Which hyperparameter optimization technique have you used and why?"]},{"cell_type":"markdown","metadata":{"id":"b9dcd690"},"source":["Logistic Regression is a simple, interpretable model best for linear relationships.\n","It performed decently but was outperformed by Random Forest."]},{"cell_type":"markdown","metadata":{"id":"724d098d"},"source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."]},{"cell_type":"markdown","metadata":{"id":"808e0151"},"source":["Used RandomizedSearchCV to tune C and solver.\n","\n","Why this? Faster than GridSearch, good for testing wide ranges."]},{"cell_type":"markdown","metadata":{"id":"667db347"},"source":["#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."]},{"cell_type":"markdown","metadata":{"id":"dcb74336"},"source":["Answer Here."]},{"cell_type":"markdown","metadata":{"id":"7413110b"},"source":["### ML Model - 3"]},{"cell_type":"code","metadata":{"id":"e7bf13d2"},"source":["# Import necessary libraries\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# ----------------------------\n","# Fit the Algorithm\n","# ----------------------------\n","dt_model = DecisionTreeClassifier(random_state=42)\n","dt_model.fit(X_train, y_train)\n","\n","# ----------------------------\n","# Predict on the model\n","# ----------------------------\n","y_pred_dt = dt_model.predict(X_test)\n","\n","# ----------------------------\n","# Evaluation\n","# ----------------------------\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))\n","\n","# Confusion Matrix\n","sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='Purples')\n","plt.title(\"Decision Tree - Confusion Matrix\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8e46dad2"},"source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."]},{"cell_type":"code","metadata":{"id":"f912cc69"},"source":["# Visualizing evaluation Metric Score chart\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Train Decision Tree Model\n","dt_model = DecisionTreeClassifier(random_state=42)\n","dt_model.fit(X_train, y_train)\n","y_pred_dt = dt_model.predict(X_test)\n","\n","# Evaluation\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))\n","\n","# Confusion Matrix\n","sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='Purples')\n","plt.title(\"Decision Tree - Confusion Matrix\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"648a4b82"},"source":["#### 2. Cross- Validation & Hyperparameter Tuning"]},{"cell_type":"code","metadata":{"id":"a464771c"},"source":["from sklearn.model_selection import GridSearchCV\n","\n","# Define parameter grid\n","params_dt = {\n","    'max_depth': [5, 10, 15, None],\n","    'min_samples_split': [2, 5, 10],\n","    'criterion': ['gini', 'entropy']\n","}\n","\n","# GridSearchCV\n","grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid=params_dt, cv=3)\n","grid_dt.fit(X_train, y_train)\n","y_pred_dt_opt = grid_dt.predict(X_test)\n","\n","# Evaluation after tuning\n","print(\"Best Params:\", grid_dt.best_params_)\n","print(\"Optimized Accuracy:\", accuracy_score(y_test, y_pred_dt_opt))\n","print(\"\\nOptimized Classification Report:\\n\", classification_report(y_test, y_pred_dt_opt))\n","\n","# Confusion Matrix after tuning\n","sns.heatmap(confusion_matrix(y_test, y_pred_dt_opt), annot=True, fmt='d', cmap='Blues')\n","plt.title(\"Optimized Decision Tree - Confusion Matrix\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"59108e46"},"source":["##### Which hyperparameter optimization technique have you used and why?"]},{"cell_type":"markdown","metadata":{"id":"d131531a"},"source":["I used GridSearchCV for hyperparameter optimization of the Decision Tree model."]},{"cell_type":"markdown","metadata":{"id":"bfa9c274"},"source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."]},{"cell_type":"markdown","metadata":{"id":"6be0411a"},"source":["Yes, after applying GridSearchCV to tune the Decision Tree"]},{"cell_type":"markdown","metadata":{"id":"73bd2505"},"source":["### 1. Which Evaluation metrics did you consider for a positive business impact and why?"]},{"cell_type":"markdown","metadata":{"id":"b5ac6722"},"source":["I considered the following evaluation metrics:\n","\n","Accuracy: Measures overall correctness — important when classes are somewhat balanced.\n","\n","Precision: Ensures we don’t wrongly classify satisfied customers as unsatisfied (especially important in service feedback).\n","\n","Recall: Critical for identifying all dissatisfied customers to act on.\n","\n","F1-Score: Balances precision and recall — ideal when the dataset has class imbalance (e.g., more 4s and 5s in CSAT)."]},{"cell_type":"markdown","metadata":{"id":"a6040087"},"source":["### 2. Which ML model did you choose from the above created models as your final prediction model and why?"]},{"cell_type":"markdown","metadata":{"id":"dd0ae796"},"source":["I chose Random Forest (with GridSearchCV tuning) as the final model because:\n","\n","It had the highest accuracy (~0.89) and F1-score.\n","\n","It performs well on imbalanced datasets.\n","\n","It handles non-linear relationships between features better than logistic regression.\n","\n","It provides feature importance to explain model predictions."]},{"cell_type":"markdown","metadata":{"id":"15ca3b24"},"source":["### 3. Explain the model which you have used and the feature importance using any model explainability tool?"]},{"cell_type":"markdown","metadata":{"id":"d0801ee4"},"source":["I used Random Forest and extracted feature importance using its .feature_importances_ attribute"]},{"cell_type":"markdown","metadata":{"id":"6e4301d7"},"source":["## ***8.*** ***Future Work (Optional)***"]},{"cell_type":"markdown","metadata":{"id":"de52d0b4"},"source":["### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process."]},{"cell_type":"code","metadata":{"id":"68a908ea"},"source":["# Save the File\n","# ✅ FUTURE WORK – MODEL DEPLOYMENT USING JOBLIB\n","\n","# Step 1: Train the best model (Random Forest)\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","import joblib\n","\n","# Fit the model\n","rf_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Predict and check accuracy\n","y_pred = rf_model.predict(X_test)\n","print(\"Original Model Accuracy:\", accuracy_score(y_test, y_pred))\n","\n","# Step 2: Save the model using joblib\n","joblib.dump(rf_model, 'best_rf_model.pkl')\n","print(\"✅ Model saved successfully as 'best_rf_model.pkl'\")\n","\n","# Step 3: Load the saved model\n","loaded_model = joblib.load('best_rf_model.pkl')\n","\n","# Step 4: Sanity check - Predict again using loaded model\n","y_loaded_pred = loaded_model.predict(X_test)\n","print(\"Sanity Check Accuracy (Loaded Model):\", accuracy_score(y_test, y_loaded_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4bb57c5f"},"source":["### 2. Again Load the saved model file and try to predict unseen data for a sanity check."]},{"cell_type":"code","metadata":{"id":"ce6c1e79"},"source":["# Load the File and predict unseen data.\n","# 🔁 Load the saved model file\n","import joblib\n","loaded_model = joblib.load('best_rf_model.pkl')\n","\n","# ✅ Example: Predict on one unseen test row\n","# Select any one row from X_test or create your own\n","import pandas as pd\n","\n","unseen_data = X_test.sample(1, random_state=99)\n","print(\"Unseen input data:\\n\", unseen_data)\n","\n","# Predict using loaded model\n","prediction = loaded_model.predict(unseen_data)\n","print(\"Predicted CSAT Score for unseen data:\", prediction[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c090e0c5"},"source":["### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"]},{"cell_type":"markdown","metadata":{"id":"69bd4959"},"source":["# **Conclusion**"]},{"cell_type":"markdown","metadata":{"id":"510b0107"},"source":["In this Machine Learning Capstone Project, I successfully performed an end-to-end analysis on a customer support dataset with the goal of understanding and predicting customer satisfaction (CSAT Score). The key steps included:\n","\n","Data cleaning & preprocessing---handled missing values, encoded categorical variables, removed duplicates\n","\n","Exploratory Data Analysis (EDA)---visualized key insights across channel, product category, shift, and tenure\n","\n","Hypothesis testing---validated statistical differences across support types and agent experience levels\n","\n","Feature engineering---extracted and transformed meaningful features for modeling\n","\n","Machine learning models---implemented and evaluated:\n","\n","Random Forest (best performance)\n","\n","Logistic Regression\n","\n","Decision Tree\n","\n","Hyperparameter tuning---improved model accuracy using GridSearchCV and RandomizedSearchCV\n","\n","Model deployment---saved the best model using joblib, reloaded it, and successfully predicted on unseen data\n","\n","The best-performing model was Random Forest, achieving high accuracy and interpretability through feature importance. This model can now be integrated into business systems to automatically monitor support performance and proactively improve customer satisfaction."]},{"cell_type":"markdown","metadata":{"id":"a387746e"},"source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"]}]}